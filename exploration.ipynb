{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b89505-7681-41c0-a04c-0825db2b0e4f",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b51de48-ab5e-45f0-962b-9b0f0f1f9e1a",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374ecf9-b535-4810-9d6a-e90f39c1ba17",
   "metadata": {},
   "source": [
    "1. [Overview](##1.-Overview)\n",
    "2. [Tools](##2.-Tools)\n",
    "3. [Exploration](##3.-Exploration)\n",
    "    - [Extract](###3.1-Extract)\n",
    "    - [Transform](###3.2-Transform)\n",
    "    - [Load](###3.3-Load)\n",
    "4. Evaluation Analysis\n",
    "    - Confusion Matrix\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1 Score\n",
    "    - Accuracy\n",
    "    - Specificity\n",
    "    - Autoevaluation\n",
    "5. Building a Pipeline\n",
    "6. Tests\n",
    "7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6007c2c-42ed-457e-aeb1-b25f488efa73",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990faafc-a1b6-4dc3-abf2-4dd44fd3f782",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "\n",
    "The labellers have reviewed the output of a model, and now we would like to compare its performance against the ground truth. Attached are the results of the model run on 752 images, as well as the labels generated by the labellers. Each file lists the predictions of a single microscope image, with the filename denoting the image id. We would now like to compare the difference between the two datasets. Please write an efficient code base to output the F1 Score, Accuracy, Precision and Confusion Matrix of the dataset.\n",
    "\n",
    "**Inputs:**\n",
    "- Zip Folder\n",
    "- Folder titled \"predictions\"\n",
    "- JSON file describing predicted bounding boxes for a particular microscope image.\n",
    "- Folder titled \"Ground Truth\"\n",
    "- JSON file describing ground truth bounding boxes for a particular microscope image.\n",
    "\n",
    "**Outputs:**\n",
    "- F1 Score\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Confusion Matrix\n",
    "- Code used to generate the outputs\n",
    "\n",
    "**Submission**\n",
    "There are two ways to submit your code:\n",
    "1. Upload your repo to Github. Add ‘BioScout-Tom’ and ‘eltuna9’ as viewers to your repo.\n",
    "2. Use git bundle to create a single file of your repo, and reply to this email with the bundle attached.\n",
    "\n",
    "**Expectations:**\n",
    "- When using a Jupyter notebook, please use markdown to clearly document each section.\n",
    "- When using raw python, please make sure to commit frequently with clear commit messages, and to send through the bundled code.\n",
    "- Bonus: Extra points for any other metrics that you believe would be useful for measuring the performance of the model.\n",
    "\n",
    "**Goals:**\n",
    "In this question, we hope for you to demonstrate your knowledge of Python applied to a common ML data wrangling task, as well as modern software development practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a26613-dab6-4cab-8330-9bf6351b7884",
   "metadata": {},
   "source": [
    "## 2. Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168337de-2278-475b-85b3-e9a02e03d031",
   "metadata": {},
   "source": [
    "To get started, we'll begin by importing a few packages that will help us carry out the tasks above. The two packages not in the standard library are:\n",
    "- `pandas`\n",
    "- `scikit-learn`\n",
    "- `ibis`\n",
    "- `dvc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "71446146-5b6b-4fa3-ad76-cd87e4deb53e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from random import choice\n",
    "from sklearn import metrics as m\n",
    "import ibis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa91d708-f8d2-4872-80cb-6997190d0da2",
   "metadata": {},
   "source": [
    "## 3. Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39cb47-5170-446b-bdf6-fbdb076551e4",
   "metadata": {},
   "source": [
    "Let's begin by grabbing all of the files in each directory and evaluating a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d4bb7dd2-d06a-48ea-8478-c88e5b9a452d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/raw/predictions/6105_dbbe9a43-d891-4b7a-b048-4adbae7b5c36_2022_01_06.json',\n",
       " 'data/raw/predictions/7002_d259766e-d9bc-499e-8b54-a9e0eac33e92_2022_01_20.json',\n",
       " 'data/raw/predictions/7002_d8c71f90-ddd5-42ac-b7cf-ab81d24f9916_2022_01_11.json',\n",
       " 'data/raw/predictions/7002_7fba6770-f78d-4054-9643-45277523d7cd_2022_01_26.json']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = glob(join(\"data\", \"raw\", \"ground_truth\", \"*.json\"))\n",
    "predicted = glob(join(\"data\", \"raw\", \"predictions\", \"*.json\"))\n",
    "predicted[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d4964cb1-b36c-4686-b545-8d07d633cd95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/raw/ground_truth/7002_04fe0e08-ed2b-4fb6-bc8f-68174a83b5fb_2022_01_11.json'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample = choice(actuals)\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f19365be-35bd-42c0-a193-95f8833ca26c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': [{'bounding_box': {'h': 127.0,\n",
      "                                   'w': 368.0,\n",
      "                                   'x': 2579.0,\n",
      "                                   'y': 310.0},\n",
      "                  'id': 'c0803b85-dcae-4379-bcc8-bd2a197e25a6',\n",
      "                  'name': 'Alternaria spp.',\n",
      "                  'slot_names': ['0']},\n",
      "                 {'bounding_box': {'h': 324.0,\n",
      "                                   'w': 204.0,\n",
      "                                   'x': 208.0,\n",
      "                                   'y': 1692.0},\n",
      "                  'id': '9fdd7a8c-3595-4221-b93a-377d7734f500',\n",
      "                  'name': 'Alternaria spp.',\n",
      "                  'slot_names': ['0']}],\n",
      " 'item': {'name': '6105_eec1e5b6-1a80-44a2-9f66-5f5e550ba9d4_2022_01_25.jpeg',\n",
      "          'path': '/',\n",
      "          'slots': [{'height': 3040,\n",
      "                     'slot_name': '0',\n",
      "                     'source_files': [{'file_name': '6105_eec1e5b6-1a80-44a2-9f66-5f5e550ba9d4_2022_01_25.jpeg',\n",
      "                                       'url': 'https://darwin.v7labs.com/api/v2/teams/bioscout/uploads/9df4d3d8-a631-44bc-a6a0-ab21f5fcb61f'}],\n",
      "                     'thumbnail_url': 'https://darwin.v7labs.com/api/v2/teams/bioscout/files/cd9e0688-a52f-4aad-93a3-8de716dc2621/thumbnail',\n",
      "                     'type': 'image',\n",
      "                     'width': 4064}],\n",
      "          'source_info': {'dataset': {'dataset_management_url': 'https://darwin.v7labs.com/datasets/538883/dataset-management',\n",
      "                                      'name': 'alternaria',\n",
      "                                      'slug': 'alternaria'},\n",
      "                          'item_id': '0183d477-6025-7808-1d38-26c98f7953dc',\n",
      "                          'team': {'name': 'BioScout', 'slug': 'bioscout'},\n",
      "                          'workview_url': 'https://darwin.v7labs.com/workview?dataset=538883&item=0183d477-6025-7808-1d38-26c98f7953dc'}},\n",
      " 'schema_ref': 'https://darwin-public.s3.eu-west-1.amazonaws.com/darwin_json_2_0.schema.json',\n",
      " 'version': '2.0'}\n"
     ]
    }
   ],
   "source": [
    "with open(random_sample, \"r\") as sample:\n",
    "    data = json.load(sample)\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beaaa00-5b73-4623-bf9b-d35021008fe6",
   "metadata": {},
   "source": [
    "A much nicer way to look at this file would be through the [JSON Crack](https://jsoncrack.com/editor) editor, which would give us the following image.\n",
    "\n",
    "![jsonimage](images/jsonstruc.svg)\n",
    "\n",
    "\n",
    "Let's look at the prediction for the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8a47415f-b377-406b-bcfe-f1fd1641a464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': [{'bounding_box': {'h': 123.0,\n",
      "                                   'w': 253.0,\n",
      "                                   'x': 3655.0,\n",
      "                                   'y': 609.0},\n",
      "                  'id': '6adce333-cd9b-4545-9954-b2cd37ddd585',\n",
      "                  'name': 'Alternaria spp.',\n",
      "                  'slot_names': ['0']}],\n",
      " 'item': {'name': '7002_04fe0e08-ed2b-4fb6-bc8f-68174a83b5fb_2022_01_11.jpeg',\n",
      "          'path': '/',\n",
      "          'slots': [{'height': 3040,\n",
      "                     'slot_name': '0',\n",
      "                     'source_files': [{'file_name': '7002_04fe0e08-ed2b-4fb6-bc8f-68174a83b5fb_2022_01_11.jpeg',\n",
      "                                       'url': 'https://darwin.v7labs.com/api/v2/teams/bioscout/uploads/3e7f3272-c137-4be2-9518-270a772cc802'}],\n",
      "                     'thumbnail_url': 'https://darwin.v7labs.com/api/v2/teams/bioscout/files/672c43cb-98b2-47d6-9b97-dc5419396e6e/thumbnail',\n",
      "                     'type': 'image',\n",
      "                     'width': 4064}],\n",
      "          'source_info': {'dataset': {'dataset_management_url': 'https://darwin.v7labs.com/datasets/538883/dataset-management',\n",
      "                                      'name': 'alternaria',\n",
      "                                      'slug': 'alternaria'},\n",
      "                          'item_id': '0183d477-6028-c8a8-01c5-2c7369c9cd5d',\n",
      "                          'team': {'name': 'BioScout', 'slug': 'bioscout'},\n",
      "                          'workview_url': 'https://darwin.v7labs.com/workview?dataset=538883&item=0183d477-6028-c8a8-01c5-2c7369c9cd5d'}},\n",
      " 'schema_ref': 'https://darwin-public.s3.eu-west-1.amazonaws.com/darwin_json_2_0.schema.json',\n",
      " 'version': '2.0'}\n"
     ]
    }
   ],
   "source": [
    "# first we'll get the same file name and connect it to its respective directory\n",
    "random_prediction = join(\"data\", \"raw\", \"predictions\", random_sample.split(\"/\")[-1])\n",
    "\n",
    "with open(random_prediction, \"r\") as sample:\n",
    "    data = json.load(sample)\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5e355-1758-43a9-8529-2feef8c8d308",
   "metadata": {},
   "source": [
    "If we go to the [`schema_ref` url](https://darwin-public.s3.eu-west-1.amazonaws.com/darwin_json_2_0.schema.json) that comes up in the JSON output above, we can find more information about the files we are dealing with. Nonetheless, while the classification task at hand is one with bounding boxes rather than a **\"yes\"**, there are infectious spores in this sample, or **\"no\"**, there aren't any, we can still treat it as a binary classification task by using the absence of, or the lack thereof, the annotated boxes.\n",
    "\n",
    "Let's see how many samples lack an annotation for one or more bounding boxex from the ground truth sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "af3bcd05-15be-4d7e-b1cc-b728927a4b52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth sample has 707 images with at least one instance of a decease, 45 are healthy, and 0 are unclear!\n"
     ]
    }
   ],
   "source": [
    "box = 0\n",
    "no_box = 0\n",
    "not_sure = 0\n",
    "good_plants = []\n",
    "\n",
    "for file in actuals:\n",
    "    with open(file, \"r\") as s:\n",
    "        ac = json.load(s)\n",
    "        if ac[\"annotations\"]:\n",
    "            box += 1\n",
    "        elif ac[\"annotations\"] == []:\n",
    "            no_box += 1\n",
    "            good_plants.append(file)\n",
    "        else:\n",
    "            not_sure += 1\n",
    "            good_plants.append(file)\n",
    "print(f\"The ground truth sample has {box} images with at least one instance of a decease, {no_box} are healthy, and {not_sure} are unclear!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "30664a98-6908-458e-ab9f-ce3b3a4d2c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': [],\n",
      " 'item': {'name': '6107_a611a543-a21d-4000-abfe-a2e958d007e2_2022_01_15.jpeg',\n",
      "          'path': '/',\n",
      "          'slots': [{'height': 3040,\n",
      "                     'slot_name': '0',\n",
      "                     'source_files': [{'file_name': '6107_a611a543-a21d-4000-abfe-a2e958d007e2_2022_01_15.jpeg',\n",
      "                                       'url': 'https://darwin.v7labs.com/api/v2/teams/bioscout/uploads/d90c28aa-cce8-4732-9426-757134de9d62'}],\n",
      "                     'thumbnail_url': 'https://darwin.v7labs.com/api/v2/teams/bioscout/files/2bb07fb6-9f42-4a43-9853-720bced8bfc6/thumbnail',\n",
      "                     'type': 'image',\n",
      "                     'width': 4064}],\n",
      "          'source_info': {'dataset': {'dataset_management_url': 'https://darwin.v7labs.com/datasets/538883/dataset-management',\n",
      "                                      'name': 'alternaria',\n",
      "                                      'slug': 'alternaria'},\n",
      "                          'item_id': '0183d477-6694-51ff-ca26-00c57c4d1136',\n",
      "                          'team': {'name': 'BioScout', 'slug': 'bioscout'},\n",
      "                          'workview_url': 'https://darwin.v7labs.com/workview?dataset=538883&item=0183d477-6694-51ff-ca26-00c57c4d1136'}},\n",
      " 'schema_ref': 'https://darwin-public.s3.eu-west-1.amazonaws.com/darwin_json_2_0.schema.json',\n",
      " 'version': '2.0'}\n"
     ]
    }
   ],
   "source": [
    "with open(choice(good_plants), \"r\") as s:\n",
    "    pprint(json.load(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ed6a66a0-0091-484b-a467-e52d084e820e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in good_plants:\n",
    "    with open(file, \"r\") as s:\n",
    "        pprint(json.load(s)[\"annotations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35a512d-2d98-4f89-9b23-e1d9de6b0290",
   "metadata": {},
   "source": [
    "Now that we know a bit about the files we're dealing with, let's create a few functions to programmatically extract, transform, load, and evaluate all samples available as well as future ones.\n",
    "\n",
    "Since we'll need to save files here and there throughout the steps we'll take in this notebook, we want to start with a straightforward load function that takes in a dataframe and saves it as a parquet file.\n",
    "\n",
    "Here, we take advantage of the ipython magic command `%%writefile`, which allows turn into a script everything contained in a cell. We will use this command a few more times throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5b235dfe-c9e3-4425-8601-e167d6f4f87a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/load.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/load.py\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def save_data(data, path_out, file_name):\n",
    "    path_out = Path(path_out)\n",
    "    if not path_out.exists(): path_out.mkdir(parents=True)\n",
    "    data.to_parquet(path_out.joinpath(file_name))\n",
    "    print(f\"Successfully loaded the {file_name} table!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb7e678-87a6-4c1c-9b02-c63ce6c4bf71",
   "metadata": {},
   "source": [
    "### 3.1 Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39632e0-0e77-4440-b852-f30653bee98f",
   "metadata": {},
   "source": [
    "Next, we'll need two functions:\n",
    "- One that collects all JSON files inside a directory\n",
    "- Another that\n",
    "    1. reads each of these files\n",
    "    2. extracts the the `name` and `prediction` from it\n",
    "    3. creates a dataframe for each sample and puts them in a list\n",
    "    4. creates one dataframe for all samples\n",
    "\n",
    "While there are quite a few pieces that could be separated in the last function, the goal is a single one, to create a dataframe the ground truth and the predicted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "13007f2b-2212-43b3-b4e3-22cfa3d97fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_files(directory):\n",
    "    return glob(join(directory, \"*.json\"))\n",
    "\n",
    "\n",
    "def read_files(data_files: str) -> pd.DataFrame:\n",
    "        \n",
    "    dfs_list = []\n",
    "    \n",
    "    for file in data_files:    \n",
    "        with open(file, \"r\") as sample:\n",
    "            data = json.load(sample)\n",
    "\n",
    "        item = data[\"item\"]['name']\n",
    "\n",
    "        if data[\"annotations\"]:\n",
    "            anno_name = data[\"annotations\"][0][\"name\"]\n",
    "        else:\n",
    "            anno_name = \"Undetected\"\n",
    "        \n",
    "        df = pd.DataFrame(data=[[item, anno_name]], columns=[\"item_id\", \"class\"])\n",
    "        dfs_list.append(df)\n",
    "    \n",
    "    return pd.concat(dfs_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6f300-74e2-41c9-95af-aa4369ff3168",
   "metadata": {},
   "source": [
    "Let's make sure our functions work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ba77c265-aec9-41c9-bb93-4059f3fe4b01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/raw/ground_truth/6105_dbbe9a43-d891-4b7a-b048-4adbae7b5c36_2022_01_06.json',\n",
       " 'data/raw/ground_truth/7002_d259766e-d9bc-499e-8b54-a9e0eac33e92_2022_01_20.json',\n",
       " 'data/raw/ground_truth/7002_d8c71f90-ddd5-42ac-b7cf-ab81d24f9916_2022_01_11.json',\n",
       " 'data/raw/ground_truth/7002_7fba6770-f78d-4054-9643-45277523d7cd_2022_01_26.json',\n",
       " 'data/raw/ground_truth/6107_e475a371-228b-4e77-913b-38e0579d2837_2022_01_23.json']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = get_files(\"data/raw/ground_truth/\")\n",
    "actuals[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3adc8155-4c03-4d10-ac0f-974d5274c162",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6105_dbbe9a43-d891-4b7a-b048-4adbae7b5c36_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_d259766e-d9bc-499e-8b54-a9e0eac33e92_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_d8c71f90-ddd5-42ac-b7cf-ab81d24f9916_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_7fba6770-f78d-4054-9643-45277523d7cd_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6107_e475a371-228b-4e77-913b-38e0579d2837_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_44f7ae6c-27ff-4ea9-8ebf-7cf068161f69_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_ba67585b-8317-469c-b8eb-2f85b671fe53_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_cddf3cc2-2411-4cb1-9985-b5d3fef4c170_2022...</td>\n",
       "      <td>Undetected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6105_e5bbad9e-d694-4f2c-804c-b64072813055_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6105_5f2ab12b-22e6-4c31-90f8-605aab2663bf_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             item_id            class\n",
       "0  6105_dbbe9a43-d891-4b7a-b048-4adbae7b5c36_2022...  Alternaria spp.\n",
       "0  7002_d259766e-d9bc-499e-8b54-a9e0eac33e92_2022...  Alternaria spp.\n",
       "0  7002_d8c71f90-ddd5-42ac-b7cf-ab81d24f9916_2022...  Alternaria spp.\n",
       "0  7002_7fba6770-f78d-4054-9643-45277523d7cd_2022...  Alternaria spp.\n",
       "0  6107_e475a371-228b-4e77-913b-38e0579d2837_2022...  Alternaria spp.\n",
       "0  7002_44f7ae6c-27ff-4ea9-8ebf-7cf068161f69_2022...  Alternaria spp.\n",
       "0  7002_ba67585b-8317-469c-b8eb-2f85b671fe53_2022...  Alternaria spp.\n",
       "0  7002_cddf3cc2-2411-4cb1-9985-b5d3fef4c170_2022...       Undetected\n",
       "0  6105_e5bbad9e-d694-4f2c-804c-b64072813055_2022...  Alternaria spp.\n",
       "0  6105_5f2ab12b-22e6-4c31-90f8-605aab2663bf_2022...  Alternaria spp."
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files(actuals).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dbc114-6ccc-4d5f-b0f0-ebdee28ac62b",
   "metadata": {},
   "source": [
    "Excellent! We'll save the function in our src directory and start preparing a package in case we come up with new functions for extracting data, or in case we want to update our current ones.\n",
    "\n",
    "In this file called `extract.py`, we'll add one more function called `load_table` since we'll need to load data in subsequent steps. In addition, we'll go ahead and call the functions in the order above and save the files into a directory called `interim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ca897f64-eed3-43e8-8295-6fb4a6f4a32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/extract.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/extract.py\n",
    "\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "from load import save_data\n",
    "import json\n",
    "\n",
    "def get_files(directory):\n",
    "    return glob(join(directory, \"*.json\"))\n",
    "\n",
    "\n",
    "def read_files(data_files: str) -> pd.DataFrame:\n",
    "        \n",
    "    dfs_list = []\n",
    "    \n",
    "    for file in data_files:    \n",
    "        with open(file, \"r\") as sample:\n",
    "            data = json.load(sample)\n",
    "\n",
    "        item = data[\"item\"]['name']\n",
    "\n",
    "        if data[\"annotations\"]:\n",
    "            anno_name = data[\"annotations\"][0][\"name\"]\n",
    "        else:\n",
    "            anno_name = \"Undetected\"\n",
    "        \n",
    "        df = pd.DataFrame(data=[[item, anno_name]], columns=[\"item_id\", \"class\"])\n",
    "        dfs_list.append(df)\n",
    "    \n",
    "    return pd.concat(dfs_list, axis=0)\n",
    "\n",
    "def load_table(data_path, file_name):\n",
    "    return pd.read_parquet(join(data_path, file_name))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    actuals = get_files(\"data/raw/ground_truth/\")\n",
    "    predictions = get_files(\"data/raw/predictions/\")\n",
    "    df_truth = read_files(actuals)\n",
    "    df_preds = read_files(predictions)\n",
    "    save_data(df_truth, join(\"data\", \"interim\"), \"actuals_table.parquet\")\n",
    "    save_data(df_preds, join(\"data\", \"interim\"), \"predicted_table.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03886d1f-90da-45c3-b556-6f629707675d",
   "metadata": {},
   "source": [
    "Let's test our script to make sure it works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "45d69b3f-8936-4849-a5d4-fd24cb8b83b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the actuals_table.parquet table!\n",
      "Successfully loaded the predicted_table.parquet table!\n"
     ]
    }
   ],
   "source": [
    "!python src/extract.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "32fb9119-5d43-4dc5-8412-e5dff3c85309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6105_dbbe9a43-d891-4b7a-b048-4adbae7b5c36_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_d259766e-d9bc-499e-8b54-a9e0eac33e92_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_d8c71f90-ddd5-42ac-b7cf-ab81d24f9916_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_7fba6770-f78d-4054-9643-45277523d7cd_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6107_e475a371-228b-4e77-913b-38e0579d2837_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             item_id            class\n",
       "0  6105_dbbe9a43-d891-4b7a-b048-4adbae7b5c36_2022...  Alternaria spp.\n",
       "0  7002_d259766e-d9bc-499e-8b54-a9e0eac33e92_2022...  Alternaria spp.\n",
       "0  7002_d8c71f90-ddd5-42ac-b7cf-ab81d24f9916_2022...  Alternaria spp.\n",
       "0  7002_7fba6770-f78d-4054-9643-45277523d7cd_2022...  Alternaria spp.\n",
       "0  6107_e475a371-228b-4e77-913b-38e0579d2837_2022...  Alternaria spp."
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth = pd.read_parquet(join(\"data\", \"interim\", \"actuals_table.parquet\"))\n",
    "df_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fda25493-5dfd-4697-98a8-ef75305ed619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_78141c4d-f298-4e7f-a8fb-b28a3b9b104e_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_305dfe88-4f0a-46dc-b26f-532a374377d5_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6105_f30e970d-6952-466b-a2af-7faa77c204ea_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_9e164805-c70c-4083-8122-790a0749b6ce_2022...</td>\n",
       "      <td>Undetected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7002_5db90232-a107-434c-a136-c939a8d0ebc7_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             item_id            class\n",
       "0  7002_78141c4d-f298-4e7f-a8fb-b28a3b9b104e_2022...  Alternaria spp.\n",
       "0  7002_305dfe88-4f0a-46dc-b26f-532a374377d5_2022...  Alternaria spp.\n",
       "0  6105_f30e970d-6952-466b-a2af-7faa77c204ea_2022...  Alternaria spp.\n",
       "0  7002_9e164805-c70c-4083-8122-790a0749b6ce_2022...       Undetected\n",
       "0  7002_5db90232-a107-434c-a136-c939a8d0ebc7_2022...  Alternaria spp."
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.read_parquet(join(\"data\", \"interim\", \"predicted_table.parquet\"))\n",
    "df_preds.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a25d1e-ad22-488a-9133-7b1f52a6d77a",
   "metadata": {},
   "source": [
    "### 3.2 Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae448cf-9f86-4a8a-b5e4-928490cfd28e",
   "metadata": {},
   "source": [
    "The transform stage for this project will be very straightforward as what would be most helpful here is to combine both dataset to have the ground truth labes and the predicted ones, in two adjacent columns.\n",
    "\n",
    "We will create one function for this but note that this part of the process could be much more involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "60f1e7b9-2e9f-402c-9e07-c1be64f1238c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_truth_preds(df1, df2, **kwargs):\n",
    "    return pd.merge(left=df1, right=df2, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bfcc094f-cd8f-4323-9ed5-8d92f3ea2c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>class_truth</th>\n",
       "      <th>class_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>7002_78141c4d-f298-4e7f-a8fb-b28a3b9b104e_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>7002_305dfe88-4f0a-46dc-b26f-532a374377d5_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6105_f30e970d-6952-466b-a2af-7faa77c204ea_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>7002_9e164805-c70c-4083-8122-790a0749b6ce_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Undetected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>7002_5db90232-a107-434c-a136-c939a8d0ebc7_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               item_id      class_truth  \\\n",
       "747  7002_78141c4d-f298-4e7f-a8fb-b28a3b9b104e_2022...  Alternaria spp.   \n",
       "748  7002_305dfe88-4f0a-46dc-b26f-532a374377d5_2022...  Alternaria spp.   \n",
       "749  6105_f30e970d-6952-466b-a2af-7faa77c204ea_2022...  Alternaria spp.   \n",
       "750  7002_9e164805-c70c-4083-8122-790a0749b6ce_2022...  Alternaria spp.   \n",
       "751  7002_5db90232-a107-434c-a136-c939a8d0ebc7_2022...  Alternaria spp.   \n",
       "\n",
       "          class_pred  \n",
       "747  Alternaria spp.  \n",
       "748  Alternaria spp.  \n",
       "749  Alternaria spp.  \n",
       "750       Undetected  \n",
       "751  Alternaria spp.  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_truth_preds(df_truth, df_preds, left_on=\"item_id\", right_on=\"item_id\", suffixes=(\"_truth\", \"_pred\")).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f96d61c3-2575-43b9-a891-6cb077e30359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alternaria spp.    707\n",
       "Undetected          45\n",
       "Name: class_truth, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.class_truth.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1c5c41ca-66d7-4d17-9238-3da045c31b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alternaria spp.    733\n",
       "Undetected          19\n",
       "Name: class_pred, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.class_pred.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610fb07-6c4e-4d4b-b416-41f76306eeb1",
   "metadata": {},
   "source": [
    "Time to create a script to automate the process. We'll follow the same formula as before for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f5107274-a736-43d4-a088-3c248057c72b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/transform.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/transform.py\n",
    "\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from extract import load_table\n",
    "from load import save_data\n",
    "\n",
    "def merge_truth_preds(df1, df2, **kwargs):\n",
    "    return pd.merge(left=df1, right=df2, **kwargs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df1 = load_table(join(\"data\", \"interim\"), \"actuals_table.parquet\")\n",
    "    df2 = load_table(join(\"data\", \"interim\"), \"predicted_table.parquet\")\n",
    "    df_combined = merge_truth_preds(df1, df2, left_on=\"item_id\", right_on=\"item_id\", suffixes=(\"_truth\", \"_pred\"))\n",
    "    save_data(df_combined, join(\"data\", \"processed\"), \"combined_table.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcdd277-29ab-4c49-9f76-cb1f83a02121",
   "metadata": {},
   "source": [
    "Let's test our script to make sure everything is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ef53f1e1-520b-4332-a11b-f095efa77d97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the combined_table.parquet table!\n"
     ]
    }
   ],
   "source": [
    "!python src/transform.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0f441a05-5aac-40f3-a3db-a346f1de3667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>class_truth</th>\n",
       "      <th>class_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>7002_78141c4d-f298-4e7f-a8fb-b28a3b9b104e_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>7002_305dfe88-4f0a-46dc-b26f-532a374377d5_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6105_f30e970d-6952-466b-a2af-7faa77c204ea_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>7002_9e164805-c70c-4083-8122-790a0749b6ce_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Undetected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>7002_5db90232-a107-434c-a136-c939a8d0ebc7_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               item_id      class_truth  \\\n",
       "747  7002_78141c4d-f298-4e7f-a8fb-b28a3b9b104e_2022...  Alternaria spp.   \n",
       "748  7002_305dfe88-4f0a-46dc-b26f-532a374377d5_2022...  Alternaria spp.   \n",
       "749  6105_f30e970d-6952-466b-a2af-7faa77c204ea_2022...  Alternaria spp.   \n",
       "750  7002_9e164805-c70c-4083-8122-790a0749b6ce_2022...  Alternaria spp.   \n",
       "751  7002_5db90232-a107-434c-a136-c939a8d0ebc7_2022...  Alternaria spp.   \n",
       "\n",
       "          class_pred  \n",
       "747  Alternaria spp.  \n",
       "748  Alternaria spp.  \n",
       "749  Alternaria spp.  \n",
       "750       Undetected  \n",
       "751  Alternaria spp.  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.read_parquet(join(\"data\", \"processed\", \"combined_table.parquet\"))\n",
    "df_merged.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aafe90-e4f6-437e-b36f-e96f612e2b01",
   "metadata": {},
   "source": [
    "### 3.3 Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b7a3b-6228-4a4b-9ba1-c7d5f94246c2",
   "metadata": {},
   "source": [
    "Note that more often than not data will be saved into a data warehouse or a data lake so that everyone in the team can access the files. With this in mind, let's update our load folder and mimic a data warehouse using DuckDB and Ibis. The former is a super fast in-memory database, and the latter is synthactic sugar for communicating with different databases.\n",
    "\n",
    "Our `create_db` function will create a DuckDB database and a table to store our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "131cb5eb-3437-43d2-8f9d-ea99fd32e343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/load.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/load.py\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ibis\n",
    "from os.path import join\n",
    "\n",
    "def create_db(path_in, path_out, file_name, table_name):\n",
    "    path = Path(path_out)\n",
    "    conn = ibis.duckdb.connect(path.joinpath(file_name))\n",
    "    conn.register(path_in, table_name=table_name)\n",
    "    print(f\"Successfully loaded the {table_name} table!\")\n",
    "\n",
    "def save_data(data, path_out, file_name):\n",
    "    path_out = Path(path_out)\n",
    "    if not path_out.exists(): path_out.mkdir(parents=True)\n",
    "    data.to_parquet(path_out.joinpath(file_name))\n",
    "    print(f\"Successfully loaded the {file_name} table!\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    create_db(\n",
    "        path_in=join(\"data\", \"processed\", \"combined_table.parquet\"),\n",
    "        path_out=join(\"data\", \"dwarehouse\"),\n",
    "        file_name=\"db_analytics.ddb\",\n",
    "        table_name=\"truth_preds_challenge\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399271c1-1e5d-44a7-89dc-fc8f214aa4e0",
   "metadata": {},
   "source": [
    "Let's test it to make sure it works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "cac625bc-5263-4436-97e8-a5ff37505ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the truth_preds_challenge table!\n"
     ]
    }
   ],
   "source": [
    "!python src/load.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "62e53c08-7f31-4c1f-adf8-36a92176693a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth_preds_challenge']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ibis\n",
    "con = ibis.duckdb.connect(join(\"data\", \"dwarehouse\", \"db_analytics.ddb\"))  # in-memory database\n",
    "con.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a235b4f8-e519-4ff9-91fc-5a0b4f36cb70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id', 'class_truth', 'class_pred', '__index_level_0__']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preds = con.table(\"truth_preds_challenge\")\n",
    "data_preds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8f359828-3916-40fc-bfee-9e78019ca247",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>class_truth</th>\n",
       "      <th>class_pred</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6105_dbbe9a43-d891-4b7a-b048-4adbae7b5c36_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7002_d259766e-d9bc-499e-8b54-a9e0eac33e92_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7002_d8c71f90-ddd5-42ac-b7cf-ab81d24f9916_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7002_7fba6770-f78d-4054-9643-45277523d7cd_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6107_e475a371-228b-4e77-913b-38e0579d2837_2022...</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>Alternaria spp.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             item_id      class_truth  \\\n",
       "0  6105_dbbe9a43-d891-4b7a-b048-4adbae7b5c36_2022...  Alternaria spp.   \n",
       "1  7002_d259766e-d9bc-499e-8b54-a9e0eac33e92_2022...  Alternaria spp.   \n",
       "2  7002_d8c71f90-ddd5-42ac-b7cf-ab81d24f9916_2022...  Alternaria spp.   \n",
       "3  7002_7fba6770-f78d-4054-9643-45277523d7cd_2022...  Alternaria spp.   \n",
       "4  6107_e475a371-228b-4e77-913b-38e0579d2837_2022...  Alternaria spp.   \n",
       "\n",
       "        class_pred  __index_level_0__  \n",
       "0  Alternaria spp.                  0  \n",
       "1  Alternaria spp.                  1  \n",
       "2  Alternaria spp.                  2  \n",
       "3  Alternaria spp.                  3  \n",
       "4  Alternaria spp.                  4  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preds.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467cdcf2-250f-44aa-b5ca-b9af84a3644e",
   "metadata": {},
   "source": [
    "Now that we have processed the data, let's get started answering the questions for the challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df134a-164c-4503-874b-031e0f688e99",
   "metadata": {},
   "source": [
    "## 4. Evaluation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d8fa7-c591-4465-be16-1d6907a8722b",
   "metadata": {},
   "source": [
    "### 4.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bd901-da25-460e-b8b9-55e50c7756a3",
   "metadata": {},
   "source": [
    "The fastest way to get started analyzing the results coming out of a classification model is via a confusion matrix (CM). CMs provide us with a $2x2$ (or bigger) matrix where the columns are represented by the actual labels, and the rows by the predictions. Each element in the table represents the intersection of the two.\n",
    "\n",
    "Here's a better way to visualize it. Imagine we are examining the predictions of a classification model sports cars.\n",
    "\n",
    "|       | Actual Sports Car | Not a Sports Car|\n",
    "|---|---|---|\n",
    "| Predicted a Sports Car  | 420 |  80 |\n",
    "| Predicted Not a Sports Car | 64 |  100 |\n",
    "\n",
    "The way we evaluate these regions is as follows.\n",
    "- `Actual Sports Car` and `Predicted a Sports Car` are considered `True Positives` since our model did a good jobs at predicting that a Ferrari is a sports car.\n",
    "- `Actual Sports Car` and `Predicted Not a Sports Car` are considered `False Negatives` since our model mistakenly said that a Ferrari was the same as a Honda CRV, not a sports car.\n",
    "- `Not a Sports Car` and `Predicted a Sports Car` are considered `False Positives` since our model predicted that Nissan Pathfinder was like a ferrari, a sports car.\n",
    "- `Not a Sports Car` and `Predicted Not a Sports Car` are considered `True Negatives` since our model did a good jobs at predicting that Honda CRVs are not sports cars.\n",
    "\n",
    "With our knowledge of confusion matrices, let's examine our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f72996ad-89d5-4064-be59-ec38d3ed58ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[688,  19],\n",
       "       [ 45,   0]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx = m.confusion_matrix(df_merged.class_truth, df_merged.class_pred)\n",
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5dadaaa9-e210-4496-8430-f7535b839f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = ConfusionMatrixDisplay(mtx)\n",
    "conf.plot(colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c7f9b-34ba-4f32-a810-fed3c10ef707",
   "metadata": {},
   "source": [
    "As you can see from the image above, our model got\n",
    "- 688 True Positives\n",
    "- 0 True Negatives\n",
    "- 45 False Negatives\n",
    "- 19 False Positives\n",
    "\n",
    "This means that, while our model did well detecting images with spores carryng a decease, it still got confused with a few images. This could potentially result in having a farmer spray some unnecessary pesticide in its farm or doing nothing at all while it should be taking action.\n",
    "\n",
    "Let's examine a few other measures that help us understand the performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d94a5f-6841-4801-8c36-5ebd71b34d36",
   "metadata": {},
   "source": [
    "### 4.2 Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f411c7-6475-4ee0-aa86-beda943af2e7",
   "metadata": {},
   "source": [
    "**What is Precision?**\n",
    "> Precision measures the percentage of samples that are correctly identified as positive out of all samples that the model identified as positive. In other words, it measures the proportion of true positives among all the samples that the model classified as positive.\n",
    "\n",
    "$precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "Given the definition above, a high precision means that the model is good at avoiding false positives. Let's evaluate the precision of ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a83c60a6-4ffa-49c7-bdfa-14c737aed4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.86"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(\n",
    "    m.precision_score(\n",
    "        df_merged.class_truth, \n",
    "        df_merged.class_pred, \n",
    "        pos_label='Alternaria spp.'\n",
    "    ) * 100,\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb440a2-023d-489b-acfe-32264cace150",
   "metadata": {},
   "source": [
    "With a precision score of 93.86%, our models does very well at correctly classifying spores that carry out deceases while avoiding misclassifying those which don't have it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129f067c-cf73-4ed7-8c66-d8ad1ae72517",
   "metadata": {},
   "source": [
    "### 4.3 Recall/Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acbd7de-639a-42df-9afa-1a408b019070",
   "metadata": {},
   "source": [
    "**What is Recall or Sencitivity?**\n",
    "> Recall measures the percentage of all positive items that are correctly identified by the model. In other words, it measures the proportion of true positives that the model correctly identified among all the samples that are actually positive.\n",
    "\n",
    "This means that if a model has a high recall it will be good at avoiding false negatives.\n",
    "\n",
    "$recall = \\frac{TP}{TP + FN}$\n",
    "\n",
    "Let's evaluate the recall of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda73b22-3711-49a0-8bcd-52146e6472a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731258840169731"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.recall_score(df_merged.class_truth, df_merged.class_pred, pos_label='Alternaria spp.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cf1a8-bd60-47ee-a6a7-e2496b1c087e",
   "metadata": {},
   "source": [
    "### 4.4 F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b109daf4-22e1-416e-bb0b-ec0277b4e3a7",
   "metadata": {},
   "source": [
    "**What is an F1 Score?**\n",
    "\n",
    "> The F1 score is a measure of a model's accuracy that combines the precision and recall metrics into a single score. It takes into account both false positives and false negatives, making it a useful metric for evaluating models that deal with imbalanced classes.\n",
    "\n",
    "- $tp$ - True Positives\n",
    "- $tn$ - True Negatives\n",
    "- $fp$ - False Positives\n",
    "- $fn$ - False Negatives\n",
    "\n",
    "**F1 Formula**\n",
    "\n",
    "$f1 = 2\\frac{ (precision)(recall)}{precision + recall} = \\frac{2 tp}{2tp + fp + fn}$\n",
    "\n",
    "Let's get the F1 Score for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "79b1d145-6064-405b-b635-23790db7ed0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.56"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(\n",
    "    m.f1_score(\n",
    "        df_merged.class_truth, \n",
    "        df_merged.class_pred, \n",
    "        pos_label='Alternaria spp.'\n",
    "    ) * 100,\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc7f8d-cf93-433f-a066-e4cd4c0d7d15",
   "metadata": {},
   "source": [
    "As with precision and recall, the higher the score the better. In particular, a higher score means that our model can perform well on imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1405ce-5ad2-4feb-92c3-8bb92cc37993",
   "metadata": {},
   "source": [
    "### 4.5 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc0f24-1d69-4cf3-9e92-489a3f015349",
   "metadata": {},
   "source": [
    "**What is Accuracy?**\n",
    "> Accuracy is a metric used to evaluate how well a classification model is able to correctly predict the class label of unseen data points, and it is defined as the ratio of the number of correct predictions to the total number of predictions. \n",
    "\n",
    "While accuracy can be a very useful metric, it mostly shines with balanced datasets. Hence why we used more appropriate metrics such as precision, recall, or F1 score above.\n",
    "\n",
    "Nonetheless, let's get the precision for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "74d57c63-194f-43c5-8a99-00aba20ee142",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.49"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(\n",
    "    m.accuracy_score(\n",
    "        df_merged.class_truth, \n",
    "        df_merged.class_pred\n",
    "    ) * 100,\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf09930-757f-465d-9c22-179ff22b8abc",
   "metadata": {},
   "source": [
    "### 4.6 Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0b1be-e663-4eea-b876-e6059931cd7e",
   "metadata": {},
   "source": [
    "One last metric we could have calculated is Specificity.\n",
    "\n",
    "**What is Specificity?**\n",
    "> Specificity is a metric used to evaluate the ability of a classification model to correctly predict the negative class, and it is represented as the proportion of true negative predictions over the total number of actual negatives.\n",
    "\n",
    "The above definition tells us that this metric is particularly useful in cases where the negative class is more important, such as in medical diagnosis, where correctly identifying healthy patients is critical. The problem with our analysis is that our **True Negatives** are 0, therefore, our specitivity will be $0$.\n",
    "\n",
    "Similar to accuracy, specificity may not be a sufficient metric in cases of class imbalance, but it is still useful for understanding the performance of our model.\n",
    "\n",
    "Even though we know it is $0$, let's use the formula to calculate it.\n",
    "\n",
    "$specificity = \\frac{tn}{tn + fp}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "dd46e257-b7d2-4963-b2ee-69bceb0e77be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx[1][1] / (mtx[1][1] + mtx[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22ae12-3bba-495c-958f-59da6451e7a5",
   "metadata": {},
   "source": [
    "### 4.7 Autoevaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d447a9e-6412-49ea-b5c8-1097a485aeed",
   "metadata": {},
   "source": [
    "Let's start by creating functions for our metrics and finalize this section by turning these into a script as we have done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "76406162-98c8-4d35-8d30-120c68bceab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics(df, y_truth, y_pred, label):\n",
    "    return dict(\n",
    "        precision=round(m.precision_score(df[y_truth], df[y_pred], pos_label=label) * 100, 2),\n",
    "        recall=round(m.recall_score(df[y_truth], df[y_pred], pos_label=label) * 100, 2),\n",
    "        f1_score=round(m.f1_score(df[y_truth], df[y_pred], pos_label=label) * 100, 2),\n",
    "        accuracy=round(m.accuracy_score(df[y_truth], df[y_pred]) * 100, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a9d8a3d5-50cb-42a9-befa-5c695c863621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 93.86, 'recall': 97.31, 'f1_score': 95.56, 'accuracy': 91.49}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = get_metrics(df_merged, \"class_truth\", \"class_pred\", 'Alternaria spp.')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "27b36a8d-d678-4f03-873c-3bf5ffb9bc8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confused_mtx(df, y_truth, y_pred):\n",
    "    return m.confusion_matrix(df[y_truth], df[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "60fce89e-46f8-45de-904d-98c36a443438",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[688,  19],\n",
       "       [ 45,   0]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mtx = confused_mtx(df_merged, \"class_truth\", \"class_pred\")\n",
    "conf_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "4d924973-76bf-4ef7-960b-6dafc54fda9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_config(metrics, mtx, path=None, file_name=None):\n",
    "    conf = OmegaConf.create({\n",
    "        \"facts\": {\n",
    "            \"sample_size\": int(sum(sum(mtx))),\n",
    "            \"healthy_preds\": int(mtx[0][0]),\n",
    "            \"wrong_preds\": int(mtx[1][0] - mtx[0][1])\n",
    "        },\n",
    "        \"metrics\": {k: float(v) for k, v in metrics.items()},\n",
    "        \"matrix\": {\n",
    "            \"true_pos\": int(mtx[0][0]),\n",
    "            \"true_neg\": int(mtx[1][1]),\n",
    "            \"false_pos\": int(mtx[0][1]),\n",
    "            \"false_neg\": int(mtx[1][0])\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    print(OmegaConf.to_yaml(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "fca22958-a912-4dd7-92be-aa96f554735e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts:\n",
      "  sample_size: 752\n",
      "  healthy_preds: 688\n",
      "  wrong_preds: 26\n",
      "metrics:\n",
      "  precision: 93.86\n",
      "  recall: 97.31\n",
      "  f1_score: 95.56\n",
      "  accuracy: 91.49\n",
      "matrix:\n",
      "  true_pos: 688\n",
      "  true_neg: 0\n",
      "  false_pos: 19\n",
      "  false_neg: 45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_config(metrics, mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ffe55-7486-4edf-a7b1-72e3e3fc79ac",
   "metadata": {},
   "source": [
    "We can now put everything together and finalize our last script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "08664f93-7f2a-42a9-a427-eb9a60fe75f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/evaluate.py\n",
    "\n",
    "import sklearn.metrics as m\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from omegaconf import OmegaConf\n",
    "from extract import load_table\n",
    "\n",
    "def get_metrics(df, y_truth, y_pred, label):\n",
    "    return dict(\n",
    "        precision=round(m.precision_score(df[y_truth], df[y_pred], pos_label=label) * 100, 2),\n",
    "        recall=round(m.recall_score(df[y_truth], df[y_pred], pos_label=label) * 100, 2),\n",
    "        f1_score=round(m.f1_score(df[y_truth], df[y_pred], pos_label=label) * 100, 2),\n",
    "        accuracy=round(m.accuracy_score(df[y_truth], df[y_pred]) * 100, 2)\n",
    "    )\n",
    "\n",
    "def confused_mtx(df, y_truth, y_pred):\n",
    "    return m.confusion_matrix(df[y_truth], df[y_pred])\n",
    "\n",
    "def generate_config(metrics, mtx, path, file_name):\n",
    "    conf = OmegaConf.create({\n",
    "        \"facts\": {\n",
    "            \"sample_size\": int(sum(sum(mtx))),\n",
    "            \"healthy_preds\": int(mtx[0][0]),\n",
    "            \"wrong_preds\": int(mtx[1][0] - mtx[0][1])\n",
    "        },\n",
    "        \"metrics\": {k: float(v) for k, v in metrics.items()},\n",
    "        \"matrix\": {\n",
    "            \"true_pos\": int(mtx[0][0]),\n",
    "            \"true_neg\": int(mtx[1][1]),\n",
    "            \"false_pos\": int(mtx[0][1]),\n",
    "            \"false_neg\": int(mtx[1][0])\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    OmegaConf.save(conf, join(path, file_name))\n",
    "    \n",
    "    print(f\"Config Successfully saved as {join(path, file_name)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_table(join(\"data\", \"processed\"), \"combined_table.parquet\")\n",
    "    metrics = get_metrics(df, \"class_truth\", \"class_pred\", 'Alternaria spp.')\n",
    "    conf_mtx = confused_mtx(df, \"class_truth\", \"class_pred\")\n",
    "    generate_config(metrics, conf_mtx, join(\"src\", \"configs\"), \"config.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575218d3-5041-4d4b-ab88-a44c760c36ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's test it to make sure everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3efebf14-efa7-49e0-a7ab-3b3d904afacc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Successfully saved as src/configs/config.yml\n"
     ]
    }
   ],
   "source": [
    "!python src/evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "5748f40e-3a05-4465-9472-f527666f44b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts:\n",
      "  sample_size: 752\n",
      "  healthy_preds: 688\n",
      "  wrong_preds: 26\n",
      "metrics:\n",
      "  precision: 93.86\n",
      "  recall: 97.31\n",
      "  f1_score: 95.56\n",
      "  accuracy: 91.49\n",
      "matrix:\n",
      "  true_pos: 688\n",
      "  true_neg: 0\n",
      "  false_pos: 19\n",
      "  false_neg: 45\n"
     ]
    }
   ],
   "source": [
    "!cat src/configs/config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7057b7-cc99-4f09-b964-050ff389c6b2",
   "metadata": {},
   "source": [
    "## 5. Building a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed692f-d1c8-4c05-95f8-c3b59f50c4dd",
   "metadata": {},
   "source": [
    "We will be using dvc to create a reproducible pipeline, version, and cache artefacts.\n",
    "\n",
    "In order for us to create a pipeline via different stages, we need to have run the following commands first (no need to do this since you probably cloned this repo):\n",
    "- `dvc init`\n",
    "- `dvc remote add -d local_data_lake data`\n",
    "\n",
    "Now, we are ready to create our pipeline using `dvc stage add`, which will create a `dvc.yml` file which will track the different stages of our pipeline. Using the command `dvc repro` will run our pipeline and create a file called, `dvc.lock`, which will take care of versioning each component of it.\n",
    "\n",
    "If you want to run these files for the first time you can either remove them with \n",
    "```sh\n",
    "rm dvc.yml dvc.lock\n",
    "```\n",
    "or you can add `--force` in each of the steps, for example,\n",
    "```sh\n",
    "dvc stage add --force --name extract\n",
    "```\n",
    "or you can change some of the parameters like\n",
    "```sh\n",
    "dvc stage add --force --name extract \\\n",
    "    --deps data/raw/ground_truth/ \\\n",
    "    --deps data/raw/predictions/ \\\n",
    "    --outs your/data/dir/and/file.parquet \\\n",
    "    --outs your/data/dir/and/file.parquet \\\n",
    "    python src/extract.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24cbaaea-bc9d-4a57-a1c4-f64a33900130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifying stage 'extract' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "dvc stage add --force --name extract \\\n",
    "    --deps data/raw/ground_truth/ \\\n",
    "    --deps data/raw/predictions/ \\\n",
    "    --outs data/interim/actuals_table.parquet \\\n",
    "    --outs data/interim/predicted_table.parquet \\\n",
    "    python src/extract.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be562b-199b-4d45-98f6-c74db2ac8791",
   "metadata": {},
   "source": [
    "Let's make sure our pipeline works by calling `dvc repro`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98074ea0-181b-4f09-9bfe-9a82d0ad6523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  extract:\n",
      "    cmd: python src/extract.py\n",
      "    deps:\n",
      "    - data/raw/ground_truth/\n",
      "    - data/raw/predictions/\n",
      "    outs:\n",
      "    - data/interim/actuals_table.parquet\n",
      "    - data/interim/predicted_table.parquet\n"
     ]
    }
   ],
   "source": [
    "!cat dvc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "056a026e-0253-4969-94e7-5fb546beff4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stage 'extract':                                                        \n",
      "> python src/extract.py\n",
      "Successfully loaded the actuals_table.parquet table!\n",
      "Successfully loaded the predicted_table.parquet table!\n",
      "Generating lock file 'dvc.lock'                                                 \n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32678ac6-cf67-465d-a70f-7c7e2f5006cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
